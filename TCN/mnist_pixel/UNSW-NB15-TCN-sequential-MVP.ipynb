{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "from TCN.mnist_pixel.utils import data_generator\n",
    "from TCN.mnist_pixel.model import TCN\n",
    "import numpy as np\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not needed\n",
    "def customOneHotEncoder(data):\n",
    "    dataAdjust = data.ljust(200,'0')[:200] # padding if not of length and adjusting the data lenght to get a 200x39 input matrix\n",
    "    # define universe of possible input values\n",
    "    alphabet = '0123456789abcdefghijklmnopqrstuvwxyz,._-/+'\n",
    "    # define a mapping of chars to integers\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "    # integer encode input data\n",
    "    integer_encoded = [char_to_int[char] for char in dataAdjust]\n",
    "    #print(integer_encoded)\n",
    "    # one hot encode\n",
    "    onehot_encoded = list()\n",
    "    for i, value in enumerate(integer_encoded):\n",
    "        letter = [0 for _ in range(len(alphabet))]\n",
    "        letter[value] = 1\n",
    "        onehot_encoded.append(letter)\n",
    "    #print(onehot_encoded) # the real encoding\n",
    "    return onehot_encoded\n",
    "\n",
    "# takes a .csv filename\n",
    "def dataPreprocessing(fileName):\n",
    "    df = pd.read_csv(fileName, header = None)\n",
    "    \n",
    "    #prepare the imput data\n",
    "    xString = df.iloc[:,:43].to_string(header=False, index=False, index_names = False).split('\\n')\n",
    "    xList = [','.join(ele.split()) for ele in xString] # gives comma separated strings for each row of DataFrame\n",
    "    xData = []\n",
    "    for string in xList:\n",
    "        stringLower = string.lower()\n",
    "        oneHot = customOneHotEncoder(stringLower)\n",
    "        xData.append(oneHot)\n",
    "    xMid = np.array(xData)\n",
    "    xArray = xMid.transpose(0,2,1) # convert xMid's dim (size, 200, 39) to (size, 39, 200)\n",
    "    \n",
    "    #prepare the label data\n",
    "    df[43] = np.where(pd.isnull(df[47]), 'Normal', 'attack') # replacing anything except 'normal' with 'attack'\n",
    "    Ydf = df[43]\n",
    "    #labelName = Ydf.unique().tolist().sort() # sorted 38 label names\n",
    "    #yArray = Ydf.str.get_dummies().to_numpy() # ndarray of shape(rows/lines, 38)\n",
    "    yArray = Ydf.to_numpy()\n",
    "    \n",
    "    assert xArray.shape[0] == yArray.shape[0], 'unequal input and label sample size'\n",
    "    \n",
    "    \n",
    "    return xArray, yArray # return processed array of input and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class UNSWDataset(Dataset):\n",
    "    def __init__(self, fileName, seq_len):\n",
    "        #self.temp = readcsv\n",
    "        self.data = pd.read_csv(fileName, header = None)\n",
    "        self.seq_len = seq_len\n",
    "        #word embedding here\n",
    "        idx= [0,1,9]\n",
    "        for i in idx:\n",
    "            self.data[i] = self.data[i].astype('category')\n",
    "            self.data[i] = self.data[i].cat.codes\n",
    "        self.num_seq = len(self.data)-self.seq_len\n",
    "        self.xArray = np.zeros((self.num_seq, 41, self.seq_len))\n",
    "        self.yArray = np.zeros(self.num_seq)\n",
    "        for i in range(len(self.data)):\n",
    "            if i >= self.seq_len:\n",
    "                self.xArray[i-self.seq_len] = self.data.iloc[i-self.seq_len:i,:-1].to_numpy().transpose()\n",
    "                #self.data replaces xarray\n",
    "                self.yArray[i-self.seq_len] = self.data.iloc[i,-1]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_seq\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # prepare x data\n",
    "        #string = list(','.join('%s' %x for x in y) for y in self.data.iloc[[idx], :47].values)\n",
    "        #stringLower = string[0].lower()\n",
    "        #xData = customOneHotEncoder(stringLower) # Dim (200, 39)\n",
    "        #xMid = np.array(xData)\n",
    "        #xArray = xMid.transpose() # should be now (39, 200)\n",
    "        \n",
    "        #xArray = self.data.iloc[idx:self.seq_len + idx,:-1].to_numpy() \n",
    "        \n",
    "        # prepate y data\n",
    "        #self.data.iloc[idx, 41] = np.where(self.data.iloc[idx, 41]=='normal', 0, 1) # replacing normals with 0 and anything else with 1\n",
    "        #yArray = np.where(pd.isnull(self.data.iloc[idx, 47]), 0, 1)\n",
    "        #yArray = self.data.iloc[idx+self.seq_len,-1]\n",
    "        #yArray = Ydf.to_numpy()\n",
    "        a = self.xArray[idx]\n",
    "        b = self.yArray[idx]\n",
    "        #assert xArray.shape == yArray.shape, 'unequal input and label sample size'\n",
    "        #if(idx>=self.seq_len):\n",
    "         #   xArray = self.data.iloc[idx-self.seq_len:idx,:-1].to_numpy() \n",
    "          #  yArray = self.data.iloc[idx,-1]\n",
    "        \n",
    "        return torch.from_numpy(self.xArray[idx]), self.yArray[idx] # returns torch tensor of x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {'batch_size': 64}\n",
    "seq_len = 270\n",
    "fileNameTrain = 'UNSW-NB15_1_reduced-16-binary-class-redcol.csv'\n",
    "fileNameTest = 'UNSW-NB15_1_reduced-16-binary-class-redcol.csv'\n",
    "datasetTrain = UNSWDataset(fileNameTrain, seq_len)\n",
    "datasetTest = UNSWDataset(fileNameTest, seq_len)\n",
    "dataGeneratorTrain = DataLoader(datasetTrain, **params)\n",
    "dataGeneratorTest = DataLoader(datasetTest, **params)\n",
    "\n",
    "#define sequence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 41, 270])\n",
      "torch.Size([64])\n",
      "torch.Size([44, 41, 270])\n",
      "torch.Size([44])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (data, target) in enumerate(dataGeneratorTrain):\n",
    "    #print (batch_idx, data, target)\n",
    "    print(data.shape)\n",
    "    print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 64, 'shuffle': True}\n",
    "filedataset = 'UNSW-NB15_1.csv'\n",
    "dataset = NSLKDDDataset(filedataset)\n",
    "total_length = dataset.__len__()\n",
    "train_length = int(0.6 * total_length)\n",
    "test_length = int(0.2 * total_length)\n",
    "val_length = total_length - train_length - test_length\n",
    "datasetTrain, datasetVal, datasetTest = torch.utils.data.random_split(dataset, [train_length, val_length, test_length])\n",
    "dataGeneratorTrain = DataLoader(datasetTrain, **params)\n",
    "dataGeneratorTest = DataLoader(datasetTest, **params)\n",
    "dataGeneratorVal = DataLoader(datasetVal, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lromo\\OneDrive\\Documents\\virtualenvs\\netsec\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3338: DtypeWarning: Columns (1,3,47) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "#template\n",
    "params = {'batch_size': 64, 'shuffle': True}\n",
    "filedataset = 'UNSW-NB15_1.csv'\n",
    "dataset = NSLKDDDataset(filedataset)\n",
    "total_length = dataset.__len__()\n",
    "train_length = int(0.6 * total_length)\n",
    "test_length = int(0.2 * total_length)\n",
    "val_length = total_length - train_length - test_length\n",
    "datasetTrain, datasetVal, datasetTest = torch.utils.data.random_split(dataset, [train_length, val_length, test_length])\n",
    "dataGeneratorTrain = DataLoader(datasetTrain, **params)\n",
    "dataGeneratorTest = DataLoader(datasetTest, **params)\n",
    "dataGeneratorVal = DataLoader(datasetVal, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetTrain.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './data/mnist'\n",
    "batch_size = 64\n",
    "n_classes = 2\n",
    "input_channels = 41\n",
    "seq_length = 270\n",
    "epochs = 10\n",
    "steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader, test_loader = data_generator(root, batch_size)\n",
    "\n",
    "permute = torch.Tensor(np.random.permutation(784).astype(np.float64)).long()\n",
    "channel_sizes = [32] * 6 #hidden nodes times levels \n",
    "kernel_size = 5\n",
    "nheads = 1\n",
    "\n",
    "model = TCN(input_channels, n_classes, channel_sizes, kernel_size=kernel_size, dropout=0.25)\n",
    "#input_size, output_size, num_channels, \n",
    "#kernel_size, dropout, num_sub_blocks, temp_attn, nheads, en_res,                              num_sub_blocks\n",
    "#conv, key_size\n",
    "#\n",
    "# nheads, key_size\n",
    "\n",
    "\n",
    "lr = 1e-9\n",
    "optimizer = getattr(optim, 'Adam')(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(ep):\n",
    "    global steps\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(dataGeneratorTrain):\n",
    "        #print('data Shape: {} target shape: {} data type: {}'.format(data.shape, target.shape, type(data)))\n",
    "        optimizer.zero_grad()\n",
    "        #print(data.shape)\n",
    "        data = data.view(-1, input_channels, seq_length)\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        #print('data Shape: {} target shape: {} data type: {}'.format(data.shape, target.shape, type(data)))\n",
    "        #print(target)\n",
    "        optimizer.zero_grad()\n",
    "        #print(data[0])\n",
    "        data = data.type(torch.FloatTensor)\n",
    "        output = model(data)\n",
    "        #print(output.shape)\n",
    "        target = target.type(torch.LongTensor)\n",
    "        loss1 = torch.nn.CrossEntropyLoss()\n",
    "        loss = F.nll_loss(output, target) # negative log likelihood\n",
    "        loss = loss1(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss\n",
    "        steps += seq_length\n",
    "        #print(batch_idx)\n",
    "        if batch_idx > 0 and batch_idx % 50 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tSteps: {}'.format(\n",
    "                ep, batch_idx * batch_size, len(dataGeneratorTrain.dataset),\n",
    "                100. * batch_idx / len(dataGeneratorTrain), train_loss.item()/100, steps))\n",
    "            train_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in dataGeneratorTest:\n",
    "            model.eval()\n",
    "            #print('checkpoint 1')\n",
    "            #data = data.view(-1, input_channels, seq_length)\n",
    "            #print('checkpoint 2')\n",
    "            data = data.type(torch.FloatTensor)\n",
    "            #print('checkpoint 3')\n",
    "            target = target.type(torch.LongTensor)\n",
    "            #print('checkpoint 4')\n",
    "            data, target = Variable(data, volatile=True), Variable(target)\n",
    "            #print('checkpoint 5')\n",
    "            output = model(data)\n",
    "            #print('checkpoint 6')\n",
    "            #loss1 = torch.nn.CrossEntropyLoss()\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            #print('checkpoint 7')\n",
    "            #test_loss += loss1(output, target).item()\n",
    "            #print(output.data.max(1, keepdim=True)[1])\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            #print('checkpoint 8')\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "            #print('checkpoint 9')\n",
    "\n",
    "        test_loss /= len(dataGeneratorTest.dataset)\n",
    "        #print('checkpoint 10')\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, correct, len(dataGeneratorTest.dataset),\n",
    "            100. * correct / len(dataGeneratorTest.dataset)))\n",
    "        return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [3200/40492 (8%)]\tLoss: 5666965.760000\tSteps: 13770\n",
      "Train Epoch: 1 [6400/40492 (16%)]\tLoss: 6273176.320000\tSteps: 27270\n",
      "Train Epoch: 1 [9600/40492 (24%)]\tLoss: 7936727.680000\tSteps: 40770\n",
      "Train Epoch: 1 [12800/40492 (32%)]\tLoss: 8146849.280000\tSteps: 54270\n",
      "Train Epoch: 1 [16000/40492 (39%)]\tLoss: 7526954.240000\tSteps: 67770\n",
      "Train Epoch: 1 [19200/40492 (47%)]\tLoss: 6164496.000000\tSteps: 81270\n",
      "Train Epoch: 1 [22400/40492 (55%)]\tLoss: 4891112.320000\tSteps: 94770\n",
      "Train Epoch: 1 [25600/40492 (63%)]\tLoss: 5706103.040000\tSteps: 108270\n",
      "Train Epoch: 1 [28800/40492 (71%)]\tLoss: 6708122.240000\tSteps: 121770\n",
      "Train Epoch: 1 [32000/40492 (79%)]\tLoss: 4558048.320000\tSteps: 135270\n",
      "Train Epoch: 1 [35200/40492 (87%)]\tLoss: 5506942.720000\tSteps: 148770\n",
      "Train Epoch: 1 [38400/40492 (95%)]\tLoss: 4969008.320000\tSteps: 162270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lromo\\OneDrive\\Documents\\virtualenvs\\netsec\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  \n",
      "C:\\Users\\lromo\\OneDrive\\Documents\\virtualenvs\\netsec\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 6304513.7296, Accuracy: 37209/40492 (92%)\n",
      "\n",
      "Train Epoch: 2 [3200/40492 (8%)]\tLoss: 2352737.600000\tSteps: 184680\n",
      "Train Epoch: 2 [6400/40492 (16%)]\tLoss: 4354569.280000\tSteps: 198180\n",
      "Train Epoch: 2 [9600/40492 (24%)]\tLoss: 5471733.120000\tSteps: 211680\n",
      "Train Epoch: 2 [12800/40492 (32%)]\tLoss: 5172636.800000\tSteps: 225180\n",
      "Train Epoch: 2 [16000/40492 (39%)]\tLoss: 4903149.760000\tSteps: 238680\n",
      "Train Epoch: 2 [19200/40492 (47%)]\tLoss: 3807017.280000\tSteps: 252180\n",
      "Train Epoch: 2 [22400/40492 (55%)]\tLoss: 2817881.920000\tSteps: 265680\n",
      "Train Epoch: 2 [25600/40492 (63%)]\tLoss: 3533516.800000\tSteps: 279180\n",
      "Train Epoch: 2 [28800/40492 (71%)]\tLoss: 4342909.440000\tSteps: 292680\n",
      "Train Epoch: 2 [32000/40492 (79%)]\tLoss: 3234210.880000\tSteps: 306180\n",
      "Train Epoch: 2 [35200/40492 (87%)]\tLoss: 3728728.960000\tSteps: 319680\n",
      "Train Epoch: 2 [38400/40492 (95%)]\tLoss: 3325001.600000\tSteps: 333180\n",
      "\n",
      "Test set: Average loss: 4075160.2550, Accuracy: 37248/40492 (92%)\n",
      "\n",
      "Train Epoch: 3 [3200/40492 (8%)]\tLoss: 1516120.960000\tSteps: 355590\n",
      "Train Epoch: 3 [6400/40492 (16%)]\tLoss: 2718270.080000\tSteps: 369090\n",
      "Train Epoch: 3 [9600/40492 (24%)]\tLoss: 3637757.760000\tSteps: 382590\n",
      "Train Epoch: 3 [12800/40492 (32%)]\tLoss: 3448170.880000\tSteps: 396090\n",
      "Train Epoch: 3 [16000/40492 (39%)]\tLoss: 3253422.720000\tSteps: 409590\n",
      "Train Epoch: 3 [19200/40492 (47%)]\tLoss: 2800837.760000\tSteps: 423090\n",
      "Train Epoch: 3 [22400/40492 (55%)]\tLoss: 2149980.800000\tSteps: 436590\n",
      "Train Epoch: 3 [25600/40492 (63%)]\tLoss: 2552038.400000\tSteps: 450090\n",
      "Train Epoch: 3 [28800/40492 (71%)]\tLoss: 3059902.720000\tSteps: 463590\n",
      "Train Epoch: 3 [32000/40492 (79%)]\tLoss: 2161157.600000\tSteps: 477090\n",
      "Train Epoch: 3 [35200/40492 (87%)]\tLoss: 2308818.880000\tSteps: 490590\n",
      "Train Epoch: 3 [38400/40492 (95%)]\tLoss: 2541847.200000\tSteps: 504090\n",
      "\n",
      "Test set: Average loss: 2678640.5430, Accuracy: 37222/40492 (92%)\n",
      "\n",
      "Train Epoch: 4 [3200/40492 (8%)]\tLoss: 998002.080000\tSteps: 526500\n",
      "Train Epoch: 4 [6400/40492 (16%)]\tLoss: 1942849.280000\tSteps: 540000\n",
      "Train Epoch: 4 [9600/40492 (24%)]\tLoss: 2489217.440000\tSteps: 553500\n",
      "Train Epoch: 4 [12800/40492 (32%)]\tLoss: 2382093.760000\tSteps: 567000\n",
      "Train Epoch: 4 [16000/40492 (39%)]\tLoss: 2416652.320000\tSteps: 580500\n",
      "Train Epoch: 4 [19200/40492 (47%)]\tLoss: 1995502.880000\tSteps: 594000\n",
      "Train Epoch: 4 [22400/40492 (55%)]\tLoss: 1415126.560000\tSteps: 607500\n",
      "Train Epoch: 4 [25600/40492 (63%)]\tLoss: 1797812.160000\tSteps: 621000\n",
      "Train Epoch: 4 [28800/40492 (71%)]\tLoss: 2376970.240000\tSteps: 634500\n",
      "Train Epoch: 4 [32000/40492 (79%)]\tLoss: 1617893.760000\tSteps: 648000\n",
      "Train Epoch: 4 [35200/40492 (87%)]\tLoss: 1881255.520000\tSteps: 661500\n",
      "Train Epoch: 4 [38400/40492 (95%)]\tLoss: 1840809.760000\tSteps: 675000\n",
      "\n",
      "Test set: Average loss: 1922752.4259, Accuracy: 37209/40492 (92%)\n",
      "\n",
      "Train Epoch: 5 [3200/40492 (8%)]\tLoss: 883213.520000\tSteps: 697410\n",
      "Train Epoch: 5 [6400/40492 (16%)]\tLoss: 1444173.600000\tSteps: 710910\n",
      "Train Epoch: 5 [9600/40492 (24%)]\tLoss: 1870798.560000\tSteps: 724410\n",
      "Train Epoch: 5 [12800/40492 (32%)]\tLoss: 1831238.400000\tSteps: 737910\n",
      "Train Epoch: 5 [16000/40492 (39%)]\tLoss: 1738235.040000\tSteps: 751410\n",
      "Train Epoch: 5 [19200/40492 (47%)]\tLoss: 1506533.920000\tSteps: 764910\n",
      "Train Epoch: 5 [22400/40492 (55%)]\tLoss: 1034226.080000\tSteps: 778410\n",
      "Train Epoch: 5 [25600/40492 (63%)]\tLoss: 1316466.320000\tSteps: 791910\n",
      "Train Epoch: 5 [28800/40492 (71%)]\tLoss: 1720048.640000\tSteps: 805410\n",
      "Train Epoch: 5 [32000/40492 (79%)]\tLoss: 1199014.640000\tSteps: 818910\n",
      "Train Epoch: 5 [35200/40492 (87%)]\tLoss: 1423081.760000\tSteps: 832410\n",
      "Train Epoch: 5 [38400/40492 (95%)]\tLoss: 1490006.880000\tSteps: 845910\n",
      "\n",
      "Test set: Average loss: 1415072.8882, Accuracy: 37194/40492 (92%)\n",
      "\n",
      "Train Epoch: 6 [3200/40492 (8%)]\tLoss: 586152.960000\tSteps: 868320\n",
      "Train Epoch: 6 [6400/40492 (16%)]\tLoss: 1166642.240000\tSteps: 881820\n",
      "Train Epoch: 6 [9600/40492 (24%)]\tLoss: 1330672.560000\tSteps: 895320\n",
      "Train Epoch: 6 [12800/40492 (32%)]\tLoss: 1335380.320000\tSteps: 908820\n",
      "Train Epoch: 6 [16000/40492 (39%)]\tLoss: 1300683.200000\tSteps: 922320\n",
      "Train Epoch: 6 [19200/40492 (47%)]\tLoss: 1071558.480000\tSteps: 935820\n",
      "Train Epoch: 6 [22400/40492 (55%)]\tLoss: 741447.200000\tSteps: 949320\n",
      "Train Epoch: 6 [25600/40492 (63%)]\tLoss: 1058046.960000\tSteps: 962820\n",
      "Train Epoch: 6 [28800/40492 (71%)]\tLoss: 1333485.440000\tSteps: 976320\n",
      "Train Epoch: 6 [32000/40492 (79%)]\tLoss: 992887.120000\tSteps: 989820\n",
      "Train Epoch: 6 [35200/40492 (87%)]\tLoss: 1141805.440000\tSteps: 1003320\n",
      "Train Epoch: 6 [38400/40492 (95%)]\tLoss: 1136228.400000\tSteps: 1016820\n",
      "\n",
      "Test set: Average loss: 1068989.7580, Accuracy: 37147/40492 (92%)\n",
      "\n",
      "Train Epoch: 7 [3200/40492 (8%)]\tLoss: 454102.440000\tSteps: 1039230\n",
      "Train Epoch: 7 [6400/40492 (16%)]\tLoss: 872918.480000\tSteps: 1052730\n",
      "Train Epoch: 7 [9600/40492 (24%)]\tLoss: 1064842.080000\tSteps: 1066230\n",
      "Train Epoch: 7 [12800/40492 (32%)]\tLoss: 1087676.720000\tSteps: 1079730\n",
      "Train Epoch: 7 [16000/40492 (39%)]\tLoss: 998037.360000\tSteps: 1093230\n",
      "Train Epoch: 7 [19200/40492 (47%)]\tLoss: 790380.320000\tSteps: 1106730\n",
      "Train Epoch: 7 [22400/40492 (55%)]\tLoss: 642345.840000\tSteps: 1120230\n",
      "Train Epoch: 7 [25600/40492 (63%)]\tLoss: 848372.480000\tSteps: 1133730\n",
      "Train Epoch: 7 [28800/40492 (71%)]\tLoss: 1091413.280000\tSteps: 1147230\n",
      "Train Epoch: 7 [32000/40492 (79%)]\tLoss: 705942.640000\tSteps: 1160730\n",
      "Train Epoch: 7 [35200/40492 (87%)]\tLoss: 893940.560000\tSteps: 1174230\n",
      "Train Epoch: 7 [38400/40492 (95%)]\tLoss: 872342.720000\tSteps: 1187730\n",
      "\n",
      "Test set: Average loss: 811908.4193, Accuracy: 37104/40492 (92%)\n",
      "\n",
      "Train Epoch: 8 [3200/40492 (8%)]\tLoss: 356585.280000\tSteps: 1210140\n",
      "Train Epoch: 8 [6400/40492 (16%)]\tLoss: 641396.480000\tSteps: 1223640\n",
      "Train Epoch: 8 [9600/40492 (24%)]\tLoss: 874100.320000\tSteps: 1237140\n",
      "Train Epoch: 8 [12800/40492 (32%)]\tLoss: 835083.680000\tSteps: 1250640\n",
      "Train Epoch: 8 [16000/40492 (39%)]\tLoss: 760136.080000\tSteps: 1264140\n",
      "Train Epoch: 8 [19200/40492 (47%)]\tLoss: 701627.520000\tSteps: 1277640\n",
      "Train Epoch: 8 [22400/40492 (55%)]\tLoss: 464389.840000\tSteps: 1291140\n",
      "Train Epoch: 8 [25600/40492 (63%)]\tLoss: 656296.960000\tSteps: 1304640\n",
      "Train Epoch: 8 [28800/40492 (71%)]\tLoss: 845539.120000\tSteps: 1318140\n",
      "Train Epoch: 8 [32000/40492 (79%)]\tLoss: 615074.600000\tSteps: 1331640\n",
      "Train Epoch: 8 [35200/40492 (87%)]\tLoss: 645087.840000\tSteps: 1345140\n",
      "Train Epoch: 8 [38400/40492 (95%)]\tLoss: 716365.040000\tSteps: 1358640\n",
      "\n",
      "Test set: Average loss: 610289.5402, Accuracy: 37048/40492 (91%)\n",
      "\n",
      "Train Epoch: 9 [3200/40492 (8%)]\tLoss: 280042.720000\tSteps: 1381050\n",
      "Train Epoch: 9 [6400/40492 (16%)]\tLoss: 522897.840000\tSteps: 1394550\n",
      "Train Epoch: 9 [9600/40492 (24%)]\tLoss: 663917.040000\tSteps: 1408050\n",
      "Train Epoch: 9 [12800/40492 (32%)]\tLoss: 649619.520000\tSteps: 1421550\n",
      "Train Epoch: 9 [16000/40492 (39%)]\tLoss: 614929.520000\tSteps: 1435050\n",
      "Train Epoch: 9 [19200/40492 (47%)]\tLoss: 522752.480000\tSteps: 1448550\n",
      "Train Epoch: 9 [22400/40492 (55%)]\tLoss: 352736.800000\tSteps: 1462050\n",
      "Train Epoch: 9 [25600/40492 (63%)]\tLoss: 540637.320000\tSteps: 1475550\n",
      "Train Epoch: 9 [28800/40492 (71%)]\tLoss: 673543.440000\tSteps: 1489050\n",
      "Train Epoch: 9 [32000/40492 (79%)]\tLoss: 499710.960000\tSteps: 1502550\n",
      "Train Epoch: 9 [35200/40492 (87%)]\tLoss: 610334.520000\tSteps: 1516050\n",
      "Train Epoch: 9 [38400/40492 (95%)]\tLoss: 566413.520000\tSteps: 1529550\n",
      "\n",
      "Test set: Average loss: 474610.8855, Accuracy: 37026/40492 (91%)\n",
      "\n",
      "Train Epoch: 10 [3200/40492 (8%)]\tLoss: 235033.640000\tSteps: 1551960\n",
      "Train Epoch: 10 [6400/40492 (16%)]\tLoss: 395351.440000\tSteps: 1565460\n",
      "Train Epoch: 10 [9600/40492 (24%)]\tLoss: 513607.600000\tSteps: 1578960\n",
      "Train Epoch: 10 [12800/40492 (32%)]\tLoss: 554498.600000\tSteps: 1592460\n",
      "Train Epoch: 10 [16000/40492 (39%)]\tLoss: 437858.440000\tSteps: 1605960\n",
      "Train Epoch: 10 [19200/40492 (47%)]\tLoss: 416907.560000\tSteps: 1619460\n",
      "Train Epoch: 10 [22400/40492 (55%)]\tLoss: 295812.500000\tSteps: 1632960\n",
      "Train Epoch: 10 [25600/40492 (63%)]\tLoss: 398456.320000\tSteps: 1646460\n",
      "Train Epoch: 10 [28800/40492 (71%)]\tLoss: 520138.560000\tSteps: 1659960\n",
      "Train Epoch: 10 [32000/40492 (79%)]\tLoss: 393605.280000\tSteps: 1673460\n",
      "Train Epoch: 10 [35200/40492 (87%)]\tLoss: 422222.320000\tSteps: 1686960\n",
      "Train Epoch: 10 [38400/40492 (95%)]\tLoss: 459555.920000\tSteps: 1700460\n",
      "\n",
      "Test set: Average loss: 358497.5857, Accuracy: 37086/40492 (92%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    for epoch in range(1, epochs+1):\n",
    "        train(epoch)\n",
    "        test()\n",
    "        if epoch % 10 == 0:\n",
    "            lr /= 10\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEED TO DO THIS ONE\n",
    "from sklearn.metrics import classification_report\n",
    "def get_metrics(dataLoader):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    f1_score = 0\n",
    "    accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in dataLoader: # just 1 batch\n",
    "            model.eval()\n",
    "            data = data.type(torch.FloatTensor)\n",
    "            target = target.type(torch.LongTensor)\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            #print(predicted)\n",
    "            total+=target.size(0)\n",
    "            correct+=(predicted == target).sum().item()\n",
    "            report = classification_report(target, predicted, output_dict=True)\n",
    "            precision += report['macro avg']['precision']\n",
    "            recall += report['macro avg']['recall']\n",
    "            f1_score += report['macro avg']['f1-score']\n",
    "            accuracy += report['accuracy']\n",
    "            print(report)\n",
    "    print(\"Precision: {}, Recall: {}, F1-Score: {}, Accuracy: {}, AccuracyCust: {}\".format(precision, recall, f1_score, accuracy, correct/total))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for now don't do thisone\n",
    "#fileNameVal = 'UNSW_NB15_testing-set.csv'\n",
    "#datasetVal = NSLKDDDataset(fileNameVal)\n",
    "params = {'batch_size': 22544, 'shuffle': True}\n",
    "dataGeneratorVal = DataLoader(datasetVal, **params)\n",
    "#RuntimeError: expected scalar type Int but found Float\n",
    "#get_metrics(dataGeneratorVal)\n",
    "def val():\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in dataGeneratorVal:\n",
    "            model.eval()\n",
    "            #data = data.view(-1, input_channels, seq_length)\n",
    "            data = data.type(torch.FloatTensor)\n",
    "            target = target.type(torch.LongTensor)\n",
    "            data, target = Variable(data, volatile=True), Variable(target)\n",
    "            output = model(data)\n",
    "            #loss1 = torch.nn.CrossEntropyLoss()\n",
    "            #test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            #test_loss += loss1(output, target).item()\n",
    "            #print(output.data.max(1, keepdim=True)[1])\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            print(pred)\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "        test_loss /= len(dataGeneratorTest.dataset)\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, correct, len(dataGeneratorVal.dataset),\n",
    "            100. * correct / len(dataGeneratorVal.dataset)))\n",
    "        return test_loss\n",
    "\n",
    "val()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 0.999888706697631, 'recall': 0.9937102280687524, 'f1-score': 0.9967898933416175, 'support': 135617}, '1': {'precision': 0.8366526235158943, 'recall': 0.9965784671532847, 'f1-score': 0.9096398084530501, 'support': 4384}, 'accuracy': 0.9938000442853979, 'macro avg': {'precision': 0.9182706651067627, 'recall': 0.9951443476110186, 'f1-score': 0.9532148508973338, 'support': 140001}, 'weighted avg': {'precision': 0.9947771218613174, 'recall': 0.9938000442853979, 'f1-score': 0.9940608701764154, 'support': 140001}}\n",
      "Precision: 0.9182706651067627, Recall: 0.9951443476110186, F1-Score: 0.9532148508973338, Accuracy: 0.9938000442853979, AccuracyCust: 0.9938000442853979\n"
     ]
    }
   ],
   "source": [
    "#do this one last\n",
    "params = {'batch_size': datasetVal.__len__(), 'shuffle': True}\n",
    "dataGeneratorVal = DataLoader(datasetVal, **params)\n",
    "get_metrics(dataGeneratorVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 0.9998960607005509, 'recall': 0.9939043289596032, 'f1-score': 0.9968911917098446, 'support': 135506}, '1': {'precision': 0.8443271767810027, 'recall': 0.9968847352024922, 'f1-score': 0.9142857142857144, 'support': 4494}, 'accuracy': 0.994, 'macro avg': {'precision': 0.9221116187407767, 'recall': 0.9953945320810478, 'f1-score': 0.9555884529977795, 'support': 140000}, 'weighted avg': {'precision': 0.9949022995267334, 'recall': 0.994, 'f1-score': 0.99423955588453, 'support': 140000}}\n",
      "Precision: 0.9221116187407767, Recall: 0.9953945320810478, F1-Score: 0.9555884529977795, Accuracy: 0.994, AccuracyCust: 0.994\n"
     ]
    }
   ],
   "source": [
    "#do this one\n",
    "params = {'batch_size': datasetTest.__len__(), 'shuffle': True}\n",
    "dataGeneratorTest = DataLoader(datasetTest, **params)\n",
    "get_metrics(dataGeneratorTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"tcn_unsw.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40762</td>\n",
       "      <td>40762</td>\n",
       "      <td>40762.000000</td>\n",
       "      <td>4.076200e+04</td>\n",
       "      <td>4.076200e+04</td>\n",
       "      <td>40762.000000</td>\n",
       "      <td>40762.000000</td>\n",
       "      <td>40762.000000</td>\n",
       "      <td>40762.000000</td>\n",
       "      <td>40762</td>\n",
       "      <td>...</td>\n",
       "      <td>40762.000000</td>\n",
       "      <td>40762.000000</td>\n",
       "      <td>40762.000000</td>\n",
       "      <td>40762.000000</td>\n",
       "      <td>40762.000000</td>\n",
       "      <td>40762.000000</td>\n",
       "      <td>40762.000000</td>\n",
       "      <td>40762.000000</td>\n",
       "      <td>40762.000000</td>\n",
       "      <td>40762.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>29688</td>\n",
       "      <td>29153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23280</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.114260</td>\n",
       "      <td>5.954914e+03</td>\n",
       "      <td>4.047243e+04</td>\n",
       "      <td>54.699818</td>\n",
       "      <td>47.195918</td>\n",
       "      <td>6.153157</td>\n",
       "      <td>18.010402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016044</td>\n",
       "      <td>0.017001</td>\n",
       "      <td>5.043717</td>\n",
       "      <td>4.739095</td>\n",
       "      <td>3.542245</td>\n",
       "      <td>4.039399</td>\n",
       "      <td>1.606619</td>\n",
       "      <td>1.046906</td>\n",
       "      <td>1.909327</td>\n",
       "      <td>0.079314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.039567</td>\n",
       "      <td>8.336349e+04</td>\n",
       "      <td>1.862701e+05</td>\n",
       "      <td>68.360785</td>\n",
       "      <td>62.596066</td>\n",
       "      <td>32.761024</td>\n",
       "      <td>66.327121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125648</td>\n",
       "      <td>0.148529</td>\n",
       "      <td>4.012933</td>\n",
       "      <td>3.738378</td>\n",
       "      <td>2.614704</td>\n",
       "      <td>2.996480</td>\n",
       "      <td>1.672633</td>\n",
       "      <td>0.307345</td>\n",
       "      <td>1.489764</td>\n",
       "      <td>0.270232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.600000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>5.200000e+02</td>\n",
       "      <td>3.040000e+02</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036865</td>\n",
       "      <td>1.540000e+03</td>\n",
       "      <td>1.956000e+03</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.528106</td>\n",
       "      <td>3.806000e+03</td>\n",
       "      <td>1.016800e+04</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.999527</td>\n",
       "      <td>7.219804e+06</td>\n",
       "      <td>1.465542e+07</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>2730.000000</td>\n",
       "      <td>5483.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0      1             2             3             4             5   \\\n",
       "count   40762  40762  40762.000000  4.076200e+04  4.076200e+04  40762.000000   \n",
       "unique     13      9           NaN           NaN           NaN           NaN   \n",
       "top       tcp    FIN           NaN           NaN           NaN           NaN   \n",
       "freq    29688  29153           NaN           NaN           NaN           NaN   \n",
       "mean      NaN    NaN      1.114260  5.954914e+03  4.047243e+04     54.699818   \n",
       "std       NaN    NaN      5.039567  8.336349e+04  1.862701e+05     68.360785   \n",
       "min       NaN    NaN      0.000000  4.600000e+01  0.000000e+00      0.000000   \n",
       "25%       NaN    NaN      0.004464  5.200000e+02  3.040000e+02     31.000000   \n",
       "50%       NaN    NaN      0.036865  1.540000e+03  1.956000e+03     31.000000   \n",
       "75%       NaN    NaN      0.528106  3.806000e+03  1.016800e+04     31.000000   \n",
       "max       NaN    NaN     59.999527  7.219804e+06  1.465542e+07    255.000000   \n",
       "\n",
       "                  6             7             8      9   ...            32  \\\n",
       "count   40762.000000  40762.000000  40762.000000  40762  ...  40762.000000   \n",
       "unique           NaN           NaN           NaN     13  ...           NaN   \n",
       "top              NaN           NaN           NaN      -  ...           NaN   \n",
       "freq             NaN           NaN           NaN  23280  ...           NaN   \n",
       "mean       47.195918      6.153157     18.010402    NaN  ...      0.016044   \n",
       "std        62.596066     32.761024     66.327121    NaN  ...      0.125648   \n",
       "min         0.000000      0.000000      0.000000    NaN  ...      0.000000   \n",
       "25%        29.000000      0.000000      0.000000    NaN  ...      0.000000   \n",
       "50%        29.000000      4.000000      4.000000    NaN  ...      0.000000   \n",
       "75%        29.000000      7.000000     11.000000    NaN  ...      0.000000   \n",
       "max       252.000000   2730.000000   5483.000000    NaN  ...      1.000000   \n",
       "\n",
       "                  33            34            35            36            37  \\\n",
       "count   40762.000000  40762.000000  40762.000000  40762.000000  40762.000000   \n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean        0.017001      5.043717      4.739095      3.542245      4.039399   \n",
       "std         0.148529      4.012933      3.738378      2.614704      2.996480   \n",
       "min         0.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "25%         0.000000      2.000000      2.000000      2.000000      2.000000   \n",
       "50%         0.000000      4.000000      4.000000      3.000000      3.000000   \n",
       "75%         0.000000      7.000000      7.000000      5.000000      5.000000   \n",
       "max         6.000000     30.000000     29.000000     25.000000     21.000000   \n",
       "\n",
       "                  38            39            40            41  \n",
       "count   40762.000000  40762.000000  40762.000000  40762.000000  \n",
       "unique           NaN           NaN           NaN           NaN  \n",
       "top              NaN           NaN           NaN           NaN  \n",
       "freq             NaN           NaN           NaN           NaN  \n",
       "mean        1.606619      1.046906      1.909327      0.079314  \n",
       "std         1.672633      0.307345      1.489764      0.270232  \n",
       "min         1.000000      1.000000      1.000000      0.000000  \n",
       "25%         1.000000      1.000000      1.000000      0.000000  \n",
       "50%         1.000000      1.000000      1.000000      0.000000  \n",
       "75%         1.000000      1.000000      2.000000      0.000000  \n",
       "max        19.000000      7.000000     12.000000      1.000000  \n",
       "\n",
       "[11 rows x 42 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"UNSW-NB15_1_reduced-16-binary-class-redcol.csv\", header=None)\n",
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for i in range(41):\n",
    "    print(data[i].isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40762 entries, 0 to 40761\n",
      "Data columns (total 42 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       40762 non-null  object \n",
      " 1   1       40762 non-null  object \n",
      " 2   2       40762 non-null  float64\n",
      " 3   3       40762 non-null  int64  \n",
      " 4   4       40762 non-null  int64  \n",
      " 5   5       40762 non-null  int64  \n",
      " 6   6       40762 non-null  int64  \n",
      " 7   7       40762 non-null  int64  \n",
      " 8   8       40762 non-null  int64  \n",
      " 9   9       40762 non-null  object \n",
      " 10  10      40762 non-null  float64\n",
      " 11  11      40762 non-null  float64\n",
      " 12  12      40762 non-null  int64  \n",
      " 13  13      40762 non-null  int64  \n",
      " 14  14      40762 non-null  int64  \n",
      " 15  15      40762 non-null  int64  \n",
      " 16  16      40762 non-null  int64  \n",
      " 17  17      40762 non-null  int64  \n",
      " 18  18      40762 non-null  int64  \n",
      " 19  19      40762 non-null  int64  \n",
      " 20  20      40762 non-null  int64  \n",
      " 21  21      40762 non-null  int64  \n",
      " 22  22      40762 non-null  float64\n",
      " 23  23      40762 non-null  float64\n",
      " 24  24      40762 non-null  float64\n",
      " 25  25      40762 non-null  float64\n",
      " 26  26      40762 non-null  float64\n",
      " 27  27      40762 non-null  float64\n",
      " 28  28      40762 non-null  float64\n",
      " 29  29      40762 non-null  int64  \n",
      " 30  30      40762 non-null  int64  \n",
      " 31  31      40762 non-null  int64  \n",
      " 32  32      40762 non-null  int64  \n",
      " 33  33      40762 non-null  int64  \n",
      " 34  34      40762 non-null  int64  \n",
      " 35  35      40762 non-null  int64  \n",
      " 36  36      40762 non-null  int64  \n",
      " 37  37      40762 non-null  int64  \n",
      " 38  38      40762 non-null  int64  \n",
      " 39  39      40762 non-null  int64  \n",
      " 40  40      40762 non-null  int64  \n",
      " 41  41      40762 non-null  int64  \n",
      "dtypes: float64(10), int64(29), object(3)\n",
      "memory usage: 13.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        11\n",
       "1        11\n",
       "2        11\n",
       "3        11\n",
       "4        11\n",
       "         ..\n",
       "40757    10\n",
       "40758    10\n",
       "40759    10\n",
       "40760    10\n",
       "40761    11\n",
       "Length: 40762, dtype: int8"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0] = data[0].astype('category')\n",
    "data[0].cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1] = data[1].astype('category')\n",
    "data[1].cat.codes\n",
    "data[1].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[9] = data[9].astype('category')\n",
    "data[9].cat.codes\n",
    "data[9].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>132</td>\n",
       "      <td>164</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.036133</td>\n",
       "      <td>528</td>\n",
       "      <td>304</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>146</td>\n",
       "      <td>178</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>132</td>\n",
       "      <td>164</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>146</td>\n",
       "      <td>178</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1         2    3    4   5   6   7   8   9   ...  32  33  34  35  36  \\\n",
       "0  11   1  0.001055  132  164  31  29   0   0   2  ...   0   0   3   7   1   \n",
       "1  11   1  0.036133  528  304  31  29   0   0   0  ...   0   0   2   4   2   \n",
       "2  11   1  0.001119  146  178  31  29   0   0   2  ...   0   0  12   8   1   \n",
       "3  11   1  0.001209  132  164  31  29   0   0   2  ...   0   0   6   9   1   \n",
       "4  11   1  0.001169  146  178  31  29   0   0   2  ...   0   0   7   9   1   \n",
       "\n",
       "   37  38  39  40  41  \n",
       "0   3   1   1   1   0  \n",
       "1   3   1   1   2   0  \n",
       "2   2   2   1   1   0  \n",
       "3   1   1   1   1   0  \n",
       "4   1   1   1   1   0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx= [0,1,9]\n",
    "for i in idx:\n",
    "    data[i] = data[i].astype('category')\n",
    "    data[i] = data[i].cat.codes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
